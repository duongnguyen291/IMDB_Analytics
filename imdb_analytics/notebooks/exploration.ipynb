{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Định nghĩa constants\n",
    "HDFS_HOST = \"hdfs://localhost:9000\"  \n",
    "HDFS_PATH = f\"{HDFS_HOST}/hadoop/data/parquet/\"\n",
    "\n",
    "def create_spark_session(app_name=\"IMDb Analytics\"):\n",
    "    \"\"\"\n",
    "    Tạo và cấu hình SparkSession với các thiết lập phù hợp.\n",
    "    \n",
    "    Parameters:\n",
    "        app_name (str): Tên của ứng dụng Spark\n",
    "        \n",
    "    Returns:\n",
    "        SparkSession: SparkSession đã được cấu hình\n",
    "    \"\"\"\n",
    "    return SparkSession.builder \\\n",
    "        .appName(app_name) \\\n",
    "        .config(\"spark.executor.memory\", \"4g\") \\\n",
    "        .config(\"spark.driver.memory\", \"2g\") \\\n",
    "        .config(\"spark.hadoop.fs.defaultFS\", HDFS_HOST) \\\n",
    "        .config(\"spark.sql.warehouse.dir\", f\"{HDFS_HOST}/user/hive/warehouse\") \\\n",
    "        .config(\"spark.executor.cores\", \"2\") \\\n",
    "        .config(\"spark.driver.cores\", \"2\") \\\n",
    "        .config(\"spark.sql.files.maxPartitionBytes\", \"128MB\") \\\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"10\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Hàm tiện ích để kiểm tra kết nối HDFS\n",
    "def test_hdfs_connection(spark):\n",
    "    \"\"\"\n",
    "    Kiểm tra kết nối tới HDFS bằng cách đọc thử một file parquet\n",
    "    \n",
    "    Parameters:\n",
    "        spark (SparkSession): SparkSession đã được khởi tạo\n",
    "        \n",
    "    Returns:\n",
    "        bool: True nếu kết nối thành công, False nếu thất bại\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Thử đọc một file parquet bất kỳ\n",
    "        test_df = spark.read.parquet(f\"{HDFS_PATH}/title_basics_parquet\")\n",
    "        test_df.printSchema()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Lỗi kết nối HDFS: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDbDataLoader:\n",
    "    def __init__(self, spark, base_path):\n",
    "        self.spark = spark\n",
    "        self.base_path = base_path\n",
    "    \n",
    "    def load_titles(self):\n",
    "        return self.spark.read.parquet(f\"{self.base_path}/title_basics_parquet\") # basic in4 about titles\n",
    "    \n",
    "    def load_ratings(self):\n",
    "        return self.spark.read.parquet(f\"{self.base_path}/title_ratings_parquet\") # in4 about ratings and vote counts for titles\n",
    "    \n",
    "    def load_names(self):\n",
    "        return self.spark.read.parquet(f\"{self.base_path}/name_basics_parquet\") # Basic in4 about individuals\n",
    "\n",
    "    def load_akas(self):\n",
    "        return self.spark.read.parquet(f\"{self.base_path}/title_akas_parquet\") # In4 about alternative titles of movies or shows\n",
    "        \n",
    "    def load_episodes(self):\n",
    "        return self.spark.read.parquet(f\"{self.base_path}/title_episode_parquet\") # About episodoes in a series\n",
    "\n",
    "    def load_principals(self):\n",
    "        return self.spark.read.parquet(f\"{self.base_path}/title_principals_parquet\") # In4 about key indivisuals related to a title\n",
    "    \n",
    "    def load_crews(self):\n",
    "        return self.spark.read.parquet(f\"{self.base_path}/title_crew_parquet\") # In4 about the creative team behind the film\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, explode, split, when, count, collect_set, desc\n",
    "\n",
    "class MovieAnalyzer:\n",
    "    def __init__(self, movies_df, crew_df, principals_df, ratings_df):\n",
    "        \"\"\"\n",
    "        Initialize with four dataframes:\n",
    "        - movies_df: Movie information\n",
    "        - crew_df: Crew information (directors, writers)\n",
    "        - principals_df: Crew details (roles, jobs)\n",
    "        - ratings_df: Ratings information\n",
    "        \"\"\"\n",
    "        self.movies_df = movies_df\n",
    "        self.crew_df = crew_df\n",
    "        self.principals_df = principals_df\n",
    "        self.ratings_df = ratings_df\n",
    "\n",
    "    def get_genre_distribution(self):\n",
    "        \"\"\"Analyze movie genre distribution\"\"\"\n",
    "        return self.movies_df.select(\n",
    "            explode(split(\"genres\", \",\")).alias(\"genre\")\n",
    "        ).groupBy(\"genre\").count().orderBy(desc(\"count\"))\n",
    "    \n",
    "    def get_director_productivity(self):\n",
    "        \"\"\"Analyze most productive directors\"\"\"\n",
    "        return self.crew_df.select(\n",
    "            explode(split(\"directors\", \",\")).alias(\"director_id\")\n",
    "        ).filter(\n",
    "            col(\"director_id\").isNotNull()\n",
    "        ).groupBy(\"director_id\").count().orderBy(desc(\"count\")).limit(10)\n",
    "    \n",
    "    def get_job_distribution(self):\n",
    "        \"\"\"Analyze distribution of roles in film crew\"\"\"\n",
    "        return self.principals_df.groupBy(\"category\", \"job\").count().orderBy(desc(\"count\"))\n",
    "    \n",
    "    def get_multi_role_people(self):\n",
    "        \"\"\"Find people with multiple roles\"\"\"\n",
    "        return self.principals_df.groupBy(\"nconst\").agg(\n",
    "            count(\"category\").alias(\"num_roles\"),\n",
    "            collect_set(\"category\").alias(\"roles\")\n",
    "        ).orderBy(desc(\"num_roles\")).limit(10)\n",
    "    \n",
    "    def get_collaboration_network(self):\n",
    "        \"\"\"Analyze collaboration network between directors and producers\"\"\"\n",
    "        directors = self.principals_df.filter(\n",
    "            col(\"category\") == \"director\"\n",
    "        ).select(\"tconst\", \"nconst\").withColumnRenamed(\"nconst\", \"director_id\")\n",
    "        \n",
    "        producers = self.principals_df.filter(\n",
    "            col(\"category\") == \"producer\"\n",
    "        ).select(\"tconst\", \"nconst\").withColumnRenamed(\"nconst\", \"producer_id\")\n",
    "        \n",
    "        return directors.join(producers, \"tconst\").groupBy(\n",
    "            \"director_id\", \"producer_id\"\n",
    "        ).count().orderBy(desc(\"count\"))\n",
    "\n",
    "    def get_top_rated_movies(self):\n",
    "        \"\"\"Get top rated movies by average rating\"\"\"\n",
    "        return self.movies_df.join(\n",
    "            self.ratings_df, \"tconst\"\n",
    "        ).select(\"primaryTitle\", \"averageRating\", \"numVotes\").orderBy(\n",
    "            desc(\"averageRating\"), desc(\"numVotes\")\n",
    "        ).limit(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class MovieVisualizer:\n",
    "    @staticmethod\n",
    "    def plot_genre_distribution(genre_df):\n",
    "        \"\"\"Plot genre distribution\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        data = genre_df.toPandas()\n",
    "        sns.barplot(data=data, x='genre', y='count')\n",
    "        plt.title(\"Movie Genre Distribution\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.xlabel(\"Genre\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.tight_layout()\n",
    "        return plt.gcf()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_job_distribution(job_df):\n",
    "        \"\"\"Plot job distribution in film crew\"\"\"\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        data = job_df.toPandas()\n",
    "        ax = sns.barplot(data=data, x='category', y='count', hue='job')\n",
    "        plt.title(\"Job Distribution in Film Crew\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.xlabel(\"Category\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        return plt.gcf()\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_director_productivity(director_df):\n",
    "        \"\"\"Plot top directors\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        data = director_df.toPandas()\n",
    "        sns.barplot(data=data, x='director_id', y='count')\n",
    "        plt.title(\"Top Directors by Number of Films\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.xlabel(\"Director ID\")\n",
    "        plt.ylabel(\"Number of Films\")\n",
    "        plt.tight_layout()\n",
    "        return plt.gcf()\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_top_rated_movies(movie_df):\n",
    "        \"\"\"Plot top-rated movies\"\"\"\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        data = movie_df.toPandas()\n",
    "        sns.barplot(data=data, x='primaryTitle', y='averageRating')\n",
    "        plt.title(\"Top Rated Movies\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.xlabel(\"Movie Title\")\n",
    "        plt.ylabel(\"Average Rating\")\n",
    "        plt.tight_layout()\n",
    "        return plt.gcf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def visualize_rating_variance(rating_variance_df):\n",
    "    \"\"\"\n",
    "    Visualize rating variance and average ratings across title types.\n",
    "    :param rating_variance_df: PySpark DataFrame with rating variance data\n",
    "    \"\"\"\n",
    "    rating_variance_pd = rating_variance_df.toPandas()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(rating_variance_pd['titleType'], rating_variance_pd['rating_variance'], alpha=0.7, label='Rating Variance')\n",
    "    plt.plot(rating_variance_pd['titleType'], rating_variance_pd['avg_rating'], color='r', marker='o', label='Average Rating')\n",
    "    plt.xlabel('Title Type')\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.title('Rating Variance and Average Ratings by Title Type')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_top_performers(high_performers_df):\n",
    "    \"\"\"\n",
    "    Visualize the top consistently high-performing directors and writers.\n",
    "    :param high_performers_df: PySpark DataFrame with high-performing crew members data\n",
    "    \"\"\"\n",
    "    high_performers_pd = high_performers_df.limit(10).toPandas()  # Limit to top 10 for clarity\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=high_performers_pd, x='avg_rating', y='nconst', orient='h', palette='coolwarm')\n",
    "    plt.xlabel('Average Rating')\n",
    "    plt.ylabel('Director/Writer (nconst)')\n",
    "    plt.title('Top Consistently High-Performing Directors/Writers')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_crew_correlation(crew_performance_df):\n",
    "    \"\"\"\n",
    "    Visualize correlation between crew members (directors/writers) and title ratings.\n",
    "    :param crew_performance_df: PySpark DataFrame with crew performance data\n",
    "    \"\"\"\n",
    "    crew_performance_pd = crew_performance_df.limit(20).toPandas()  # Limit to top 20 for visualization\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(data=crew_performance_pd, x='weighted_popularity', y='avg_rating', hue='num_titles', size='total_votes', palette='viridis')\n",
    "    plt.xlabel('Weighted Popularity')\n",
    "    plt.ylabel('Average Rating')\n",
    "    plt.title('Correlation Between Crew Members and Title Ratings')\n",
    "    plt.legend(title='Number of Titles')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_rating_distribution(rating_distribution_df):\n",
    "    \"\"\"\n",
    "    Visualize the distribution of ratings.\n",
    "    :param rating_distribution_df: PySpark DataFrame with rating distribution data\n",
    "    \"\"\"\n",
    "    rating_distribution_pd = rating_distribution_df.toPandas()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(data=rating_distribution_pd, x='averageRating', bins=20, kde=True, color='skyblue')\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Number of Titles')\n",
    "    plt.title('Distribution of IMDb Ratings')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_rating_by_title_type(avg_rating_by_title_type_df):\n",
    "    \"\"\"\n",
    "    Visualize the average ratings by title type (movie, tvseries, etc.).\n",
    "    :param avg_rating_by_title_type_df: PySpark DataFrame with average ratings by title type\n",
    "    \"\"\"\n",
    "    avg_rating_by_title_type_pd = avg_rating_by_title_type_df.toPandas()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=avg_rating_by_title_type_pd, x='titleType', y='avg_rating', palette='pastel')\n",
    "    plt.xlabel('Title Type')\n",
    "    plt.ylabel('Average Rating')\n",
    "    plt.title('Average Ratings by Title Type')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    explode, col, count, desc, avg, \n",
    "    sum , when, concat_ws,\n",
    "    split, year, struct, dense_rank,\n",
    "    var_pop,  \n",
    ")\n",
    "from pyspark.sql.types import DoubleType\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class AdvancedAnalysis:\n",
    "    def __init__(self, spark_session):\n",
    "        \"\"\"\n",
    "        Initialize AdvancedAnalysis with a SparkSession\n",
    "        \n",
    "        :param spark_session: Active Spark session\n",
    "        \"\"\"\n",
    "        self.spark = spark_session\n",
    "    \n",
    "    def compute_genre_rating_correlation(self, title_basics_df, title_ratings_df):\n",
    "        \"\"\"\n",
    "        Compute correlation between genre and average rating\n",
    "        \n",
    "        :param title_basics_df: DataFrame with title basics\n",
    "        :param title_ratings_df: DataFrame with title ratings\n",
    "        :return: Correlation matrix of genres with ratings\n",
    "        \"\"\"\n",
    "        # One-hot encode genres\n",
    "        genre_encoded_df = (\n",
    "            title_basics_df\n",
    "            .join(title_ratings_df, 'tconst')\n",
    "            .select(\n",
    "                F.explode(F.split('genres', ',')).alias('genre'), \n",
    "                'averageRating'\n",
    "            )\n",
    "            .groupBy('genre')\n",
    "            .agg(\n",
    "                F.avg('averageRating').alias('avg_rating'),\n",
    "                F.count('*').alias('genre_count')\n",
    "            )\n",
    "            .filter(F.col('genre') != '\\\\N')\n",
    "        )\n",
    "        \n",
    "        # Prepare data for correlation\n",
    "        assembler = VectorAssembler(\n",
    "            inputCols=['avg_rating', 'genre_count'], \n",
    "            outputCol='features'\n",
    "        )\n",
    "        features_df = assembler.transform(genre_encoded_df)\n",
    "        \n",
    "        # Compute correlation matrix\n",
    "        correlation_matrix = Correlation.corr(features_df, 'features')\n",
    "        return correlation_matrix\n",
    "    \n",
    "    def analyze_crew_contribution(self, title_basics_df, title_crew_df, title_ratings_df, top_n=10):\n",
    "        \"\"\"\n",
    "        Analyze top directors and writers based on their titles' ratings\n",
    "        \n",
    "        :param title_basics_df: DataFrame with title basics\n",
    "        :param title_crew_df: DataFrame with crew information\n",
    "        :param title_ratings_df: DataFrame with title ratings\n",
    "        :param top_n: Number of top crew members to return\n",
    "        :return: DataFrame of top crew members by average title rating\n",
    "        \"\"\"\n",
    "        # Explode directors and join with basics and ratings\n",
    "        directors_performance = (\n",
    "            title_crew_df\n",
    "            .select(F.explode(F.split('directors', ',')).alias('nconst'), 'tconst')\n",
    "            .join(title_basics_df, 'tconst')\n",
    "            .join(title_ratings_df, 'tconst')\n",
    "            .groupBy('nconst')\n",
    "            .agg(\n",
    "                F.avg('averageRating').alias('avg_title_rating'),\n",
    "                F.count('*').alias('total_titles'),\n",
    "                F.collect_list('primaryTitle').alias('titles')\n",
    "            )\n",
    "            .filter(F.col('total_titles') > 3)  # Minimum 3 titles to be considered\n",
    "            .orderBy(F.desc('avg_title_rating'))\n",
    "            .limit(top_n)\n",
    "        )\n",
    "        return directors_performance\n",
    "    \n",
    "    def analyze_runtime_rating_relationship(self, title_basics_df, title_ratings_df):\n",
    "        \"\"\"\n",
    "        Explore relationship between runtime and ratings\n",
    "        \n",
    "        :param title_basics_df: DataFrame with title basics\n",
    "        :param title_ratings_df: DataFrame with title ratings\n",
    "        :return: DataFrame showing runtime-rating correlation\n",
    "        \"\"\"\n",
    "        runtime_rating_analysis = (\n",
    "            title_basics_df\n",
    "            .join(title_ratings_df, 'tconst')\n",
    "            .filter(\n",
    "                (F.col('runtimeMinutes') != '\\\\N') & \n",
    "                (F.col('runtimeMinutes').cast('int').isNotNull())\n",
    "            )\n",
    "            .select(\n",
    "                'runtimeMinutes', \n",
    "                'averageRating', \n",
    "                'titleType'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Compute correlation\n",
    "        assembler = VectorAssembler(\n",
    "            inputCols=['runtimeMinutes', 'averageRating'], \n",
    "            outputCol='features'\n",
    "        )\n",
    "        features_df = assembler.transform(runtime_rating_analysis)\n",
    "        correlation_matrix = Correlation.corr(features_df, 'features')\n",
    "        \n",
    "        return {\n",
    "            'runtime_rating_df': runtime_rating_analysis,\n",
    "            'correlation_matrix': correlation_matrix\n",
    "        }\n",
    "#bắt đầu ở đây\n",
    "    def analyze_comprehensive_genre_popularity(\n",
    "        titles_df, \n",
    "        ratings_df, \n",
    "        crew_path=None, \n",
    "        principals_path=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Comprehensive genre popularity analysis using multiple IMDb datasets\n",
    "    \n",
    "        :param titles_path: Path to title.basics.tsv.gz\n",
    "        :param ratings_path: Path to title.ratings.tsv.gz\n",
    "        :param crew_path: Optional path to title.crew.tsv.gz\n",
    "        :param principals_path: Optional path to title.principals.tsv.gz\n",
    "        :return: DataFrame with comprehensive genre popularity metrics\n",
    "        \"\"\"\n",
    "        # Initialize Spark Session\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Comprehensive Genre Popularity Analysis\") \\\n",
    "            .getOrCreate()\n",
    "    \n",
    "        # Read input files\n",
    "    \n",
    "        # Filter out adult and low-relevance titles\n",
    "        filtered_titles = titles_df.filter(\n",
    "            (col('isAdult') == '0') & \n",
    "            (col('genres') != '\\\\N') &\n",
    "            (col('titleType').isin(['movie', 'tvseries']))\n",
    "        )\n",
    "    \n",
    "    # Convert ratings to numeric, handling potential null values\n",
    "        ratings_df = ratings_df.withColumn(\n",
    "            'averageRating', \n",
    "            col('averageRating').cast(DoubleType())\n",
    "        ).withColumn(\n",
    "            'numVotes', \n",
    "            col('numVotes').cast('integer')\n",
    "        )\n",
    "    \n",
    "    # Join titles with ratings\n",
    "        titles_with_ratings = filtered_titles.join(\n",
    "            ratings_df, \n",
    "            filtered_titles['tconst'] == ratings_df['tconst'], \n",
    "            'left'\n",
    "        )\n",
    "    \n",
    "    # Optional: Join with crew data for additional insights\n",
    "        if crew_path:\n",
    "            crew_df = spark.read.csv(\n",
    "                crew_path, \n",
    "                sep='\\t', \n",
    "                header=True, \n",
    "                nullValue='\\\\N'\n",
    "            )\n",
    "            titles_with_ratings = titles_with_ratings.join(\n",
    "                crew_df, \n",
    "                titles_with_ratings['tconst'] == crew_df['tconst'], \n",
    "            'left'\n",
    "            )\n",
    "    \n",
    "    # Explode genres and aggregate\n",
    "        genre_popularity = titles_with_ratings \\\n",
    "            .select(\n",
    "                explode(col('genres').split(',')).alias('genre'),\n",
    "                col('averageRating').alias('rating'),\n",
    "                col('numVotes').alias('votes'),\n",
    "                col('titleType')\n",
    "            ) \\\n",
    "            .groupBy('genre') \\\n",
    "            .agg(\n",
    "            # Basic metrics\n",
    "                count('*').alias('total_titles'),\n",
    "                avg('rating').alias('avg_rating'),\n",
    "                sum('votes').alias('total_votes'),\n",
    "            \n",
    "            # Weighted popularity score\n",
    "            # Combine rating and vote count for a comprehensive metric\n",
    "                (avg('rating') * sum('votes')).alias('weighted_popularity'),\n",
    "            \n",
    "            # Breakdown by title type\n",
    "                count(when(col('titleType') == 'movie', 1)).alias('movie_count'),\n",
    "                count(when(col('titleType') == 'tvseries', 1)).alias('tvseries_count')\n",
    "            )\n",
    "    \n",
    "    # Calculate percentages and final popularity score\n",
    "        total_titles = filtered_titles.count()\n",
    "    \n",
    "        final_genre_popularity = genre_popularity \\\n",
    "            .withColumn('title_percentage', \n",
    "                    col('total_titles') / total_titles * 100) \\\n",
    "            .withColumn('popularity_score', \n",
    "                    col('weighted_popularity') / sum('weighted_popularity').over()) \\\n",
    "            .orderBy(desc('popularity_score'))\n",
    "    \n",
    "        return final_genre_popularity\n",
    "\n",
    "    def analyze_genre_trends(basics_path, ratings_path):\n",
    "        spark = SparkSession.builder \\\n",
    "        .appName(\"GenreTrendsAnalysis\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # Read title basics and ratings data\n",
    "        title_basics = spark.read.csv(basics_path, sep='\\t', header=True, nullValue='\\\\N')\n",
    "        title_ratings = spark.read.csv(ratings_path, sep='\\t', header=True, nullValue='\\\\N')\n",
    "    \n",
    "    # Prepare the basics dataframe\n",
    "        basics_prepared = title_basics.select(\n",
    "            col(\"tconst\"),\n",
    "            col(\"startYear\"),\n",
    "            explode(split(col(\"genres\"), \",\")).alias(\"genre\")\n",
    "        ).filter(col(\"startYear\") != \"\\\\N\")  # Remove entries without a year\n",
    "    \n",
    "    # Cast startYear to integer\n",
    "        basics_prepared = basics_prepared.withColumn(\n",
    "            \"startYear\", \n",
    "            col(\"startYear\").cast(\"integer\")\n",
    "        )\n",
    "    \n",
    "    # Join with ratings to get rating information\n",
    "        genre_trends = basics_prepared.join(\n",
    "            title_ratings, \n",
    "            \"tconst\"\n",
    "        ).select(\n",
    "            \"startYear\",\n",
    "            \"genre\",\n",
    "            \"averageRating\",\n",
    "            \"numVotes\"\n",
    "        )\n",
    "    \n",
    "        # Compute genre trends per year\n",
    "        genre_year_stats = genre_trends.groupBy(\n",
    "            \"startYear\", \n",
    "            \"genre\"\n",
    "        ).agg(\n",
    "            avg(\"averageRating\").alias(\"avg_rating\"),\n",
    "            count(\"*\").alias(\"title_count\"),\n",
    "            sum(\"numVotes\").alias(\"total_votes\")\n",
    "        )\n",
    "        \n",
    "        # Filter out very sparse genres (optional)\n",
    "        genre_popularity = genre_year_stats.filter(col(\"title_count\") > 10)\n",
    "        \n",
    "        # Find top genres by total votes for each year\n",
    "        window_spec = Window.partitionBy(\"startYear\").orderBy(desc(\"total_votes\"))\n",
    "        top_genres_by_year = genre_popularity.withColumn(\n",
    "            \"genre_rank\", \n",
    "            dense_rank().over(window_spec)\n",
    "        ).filter(col(\"genre_rank\") <= 5)\n",
    "        \n",
    "        # Action: Show top genres trend\n",
    "        top_genres_by_year.orderBy(\"startYear\", \"genre_rank\").show(100, truncate=False)\n",
    "        \n",
    "        # Optional: Save results to a CSV\n",
    "        top_genres_by_year.write.mode(\"overwrite\").csv(\n",
    "            \"genre_trends_analysis\", \n",
    "            header=True\n",
    "        )\n",
    "        \n",
    "        return top_genres_by_year\n",
    "    def analyze_genre_popularity(spark, titles_path, akas_path, ratings_path):\n",
    "        \"\"\"\n",
    "        Analyze genre popularity by region and language\n",
    "        \n",
    "        :param spark: SparkSession\n",
    "        :param titles_path: Path to title.basics.tsv.gz\n",
    "        :param akas_path: Path to title.akas.tsv.gz\n",
    "        :param ratings_path: Path to title.ratings.tsv.gz\n",
    "        :return: DataFrame with genre popularity metrics\n",
    "        \"\"\"\n",
    "        # Load datasets\n",
    "        titles_df = spark.read.option(\"sep\", \"\\t\").option(\"header\", \"true\").option(\"nullValue\", \"\\\\N\").csv(titles_path)\n",
    "        akas_df = spark.read.option(\"sep\", \"\\t\").option(\"header\", \"true\").option(\"nullValue\", \"\\\\N\").csv(akas_path)\n",
    "        ratings_df = spark.read.option(\"sep\", \"\\t\").option(\"header\", \"true\").option(\"nullValue\", \"\\\\N\").csv(ratings_path)\n",
    "        \n",
    "        # Prepare and join data\n",
    "        genre_analysis = (titles_df\n",
    "            .filter((col(\"titleType\").isin([\"movie\", \"tvSeries\"])) & (col(\"isAdult\") == 0))\n",
    "            .select(\"tconst\", explode(split(col(\"genres\"), \",\")).alias(\"genre\"))\n",
    "            .join(ratings_df, \"tconst\")\n",
    "            .join(akas_df, \"tconst\")\n",
    "            .select(\"tconst\", \"genre\", \"averageRating\", \"numVotes\", \"region\", \"language\")\n",
    "        )\n",
    "        \n",
    "        # Analyze genre popularity by region\n",
    "        genre_popularity_by_region = (genre_analysis\n",
    "            .groupBy(\"region\", \"genre\")\n",
    "            .agg(\n",
    "                count(\"tconst\").alias(\"total_titles\"),\n",
    "                avg(\"averageRating\").alias(\"avg_rating\"),\n",
    "                avg(\"numVotes\").alias(\"avg_votes\")\n",
    "            )\n",
    "            .orderBy(desc(\"total_titles\"))\n",
    "        )\n",
    "        \n",
    "        # Analyze genre popularity by language\n",
    "        genre_popularity_by_language = (genre_analysis\n",
    "            .groupBy(\"language\", \"genre\")\n",
    "            .agg(\n",
    "                count(\"tconst\").alias(\"total_titles\"),\n",
    "                avg(\"averageRating\").alias(\"avg_rating\"),\n",
    "                avg(\"numVotes\").alias(\"avg_votes\")\n",
    "            )\n",
    "            .orderBy(desc(\"total_titles\"))\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"by_region\": genre_popularity_by_region,\n",
    "            \"by_language\": genre_popularity_by_language\n",
    "        }\n",
    "    def analyze_emerging_declining_genres(\n",
    "        titles_df, \n",
    "       ratings_df, \n",
    "        crew_path=None, \n",
    "    ):\n",
    "        \"\"\"\n",
    "        Analyze emerging or declining genres based on popularity trends over time using IMDb datasets.\n",
    "\n",
    "        :param titles_path: Path to title.basics.tsv.gz\n",
    "        :param ratings_path: Path to title.ratings.tsv.gz\n",
    "        :param crew_path: Optional path to title.crew.tsv.gz\n",
    "        :param principals_path: Optional path to title.principals.tsv.gz\n",
    "        :return: DataFrame with genre popularity trends over time\n",
    "        \"\"\"\n",
    "        # Initialize Spark Session\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Emerging or Declining Genres Analysis\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        # Filter out adult and low-relevance titles\n",
    "        filtered_titles = titles_df.filter(\n",
    "            (col('isAdult') == '0') & \n",
    "            (col('genres') != '\\\\N') & \n",
    "            (col('titleType').isin(['movie', 'tvseries']))\n",
    "        )\n",
    "\n",
    "        # Convert ratings to numeric, handling potential null values\n",
    "        ratings_df = ratings_df.withColumn(\n",
    "            'averageRating', \n",
    "            col('averageRating').cast(DoubleType())\n",
    "        ).withColumn(\n",
    "            'numVotes', \n",
    "            col('numVotes').cast('integer')\n",
    "        )\n",
    "\n",
    "        # Join titles with ratings\n",
    "        titles_with_ratings = filtered_titles.join(\n",
    "            ratings_df, \n",
    "            filtered_titles['tconst'] == ratings_df['tconst'], \n",
    "            'left'\n",
    "        )\n",
    "\n",
    "        # Optional: Join with crew data for additional insights\n",
    "        if crew_path:\n",
    "            crew_df = spark.read.csv(\n",
    "                crew_path, \n",
    "                sep='\\t', \n",
    "                header=True, \n",
    "                nullValue='\\\\N'\n",
    "            )\n",
    "            titles_with_ratings = titles_with_ratings.join(\n",
    "                crew_df, \n",
    "                titles_with_ratings['tconst'] == crew_df['tconst'], \n",
    "                'left'\n",
    "            )\n",
    "\n",
    "        # Explode genres and aggregate to get genre-wise popularity metrics\n",
    "        genre_popularity = titles_with_ratings \\\n",
    "            .select(\n",
    "                explode(split(col('genres'), ',')).alias('genre'),\n",
    "                col('averageRating').alias('rating'),\n",
    "                col('numVotes').alias('votes'),\n",
    "                col('titleType'),\n",
    "                col('startYear')  # Adding startYear for time-based analysis\n",
    "            ) \\\n",
    "            .filter(col('startYear').isNotNull())  # Remove entries without a start year\n",
    "\n",
    "        # Group by genre and startYear to track trends over time\n",
    "        genre_trends = genre_popularity \\\n",
    "            .groupBy('genre', 'startYear') \\\n",
    "            .agg(\n",
    "                count('*').alias('total_titles'),\n",
    "                avg('rating').alias('avg_rating'),\n",
    "                avg('votes').alias('avg_votes'),\n",
    "                sum('votes').alias('total_votes')\n",
    "            )\n",
    "\n",
    "        # Calculate weighted popularity score\n",
    "        genre_trends = genre_trends.withColumn(\n",
    "            'weighted_popularity',\n",
    "            col('avg_rating') * col('total_votes')\n",
    "        )\n",
    "\n",
    "        # Calculate percentage of total titles per year\n",
    "        total_titles_per_year = genre_trends.groupBy('startYear').agg(\n",
    "            sum('total_titles').alias('total_titles_year')\n",
    "        )\n",
    "\n",
    "        genre_trends = genre_trends.join(\n",
    "            total_titles_per_year,\n",
    "            genre_trends['startYear'] == total_titles_per_year['startYear'],\n",
    "            'left'\n",
    "        ).withColumn(\n",
    "            'title_percentage',\n",
    "            col('total_titles') / col('total_titles_year') * 100\n",
    "        )\n",
    "\n",
    "        # Calculate trends: change in genre popularity over time\n",
    "        window_spec = Window.partitionBy('genre').orderBy('startYear')\n",
    "\n",
    "        genre_trends = genre_trends.withColumn(\n",
    "            'popularity_change',\n",
    "            col('weighted_popularity') - lag('weighted_popularity', 1).over(window_spec)\n",
    "        )\n",
    "\n",
    "        # Identify emerging genres (positive trend) and declining genres (negative trend)\n",
    "        emerging_genres = genre_trends.filter(col('popularity_change') > 0)\n",
    "        declining_genres = genre_trends.filter(col('popularity_change') < 0)\n",
    "\n",
    "        # Combine the results into one DataFrame for better insights\n",
    "        emerging_declining_genres = emerging_genres.unionByName(declining_genres)\n",
    "\n",
    "        # Order by popularity change (ascending for declining, descending for emerging)\n",
    "        final_result = emerging_declining_genres \\\n",
    "            .orderBy(\n",
    "                col('popularity_change').desc(),  # Top emerging genres first\n",
    "                col('popularity_change').asc()   # Declining genres after\n",
    "            )\n",
    "\n",
    "        return final_result\n",
    "    def analyze_top_rated_titles(\n",
    "        titles_df, \n",
    "        ratings_df, \n",
    "        crew_path=None, \n",
    "        principals_path=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Analyze top-rated titles across different categories (genres, title types) using IMDb datasets.\n",
    "\n",
    "        :param titles_path: Path to title.basics.tsv.gz\n",
    "        :param ratings_path: Path to title.ratings.tsv.gz\n",
    "        :param crew_path: Optional path to title.crew.tsv.gz\n",
    "        :param principals_path: Optional path to title.principals.tsv.gz\n",
    "        :return: DataFrame with top-rated titles by genre and title type\n",
    "        \"\"\"\n",
    "        # Initialize Spark Session\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Top-Rated Titles Analysis\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "\n",
    "        # Filter out adult content and invalid titles\n",
    "        filtered_titles = titles_df.filter(\n",
    "            (col('isAdult') == '0') & \n",
    "            (col('genres') != '\\\\N') & \n",
    "            (col('titleType').isin(['movie', 'tvseries']))\n",
    "        )\n",
    "\n",
    "        # Convert ratings to numeric types\n",
    "        ratings_df = ratings_df.withColumn(\n",
    "            'averageRating', \n",
    "            col('averageRating').cast(DoubleType())\n",
    "        ).withColumn(\n",
    "            'numVotes', \n",
    "            col('numVotes').cast('integer')\n",
    "        )\n",
    "\n",
    "        # Join titles with ratings\n",
    "        titles_with_ratings = filtered_titles.join(\n",
    "            ratings_df, \n",
    "            filtered_titles['tconst'] == ratings_df['tconst'], \n",
    "            'left'\n",
    "        )\n",
    "\n",
    "        # Optional: Join with crew data for additional insights\n",
    "        if crew_path:\n",
    "            crew_df = spark.read.csv(\n",
    "                crew_path, \n",
    "                sep='\\t', \n",
    "                header=True, \n",
    "                nullValue='\\\\N'\n",
    "            )\n",
    "            titles_with_ratings = titles_with_ratings.join(\n",
    "                crew_df, \n",
    "                titles_with_ratings['tconst'] == crew_df['tconst'], \n",
    "                'left'\n",
    "            )\n",
    "\n",
    "        # Explode genres and aggregate to get genre-wise popularity metrics\n",
    "        genre_ratings = titles_with_ratings \\\n",
    "            .select(\n",
    "                explode(split(col('genres'), ',')).alias('genre'),\n",
    "                col('averageRating').alias('rating'),\n",
    "                col('titleType')\n",
    "            )\n",
    "\n",
    "        # Get top-rated titles per genre\n",
    "        top_rated_genre = genre_ratings \\\n",
    "            .groupBy('genre') \\\n",
    "            .agg(\n",
    "                avg('rating').alias('avg_rating'),\n",
    "                count('*').alias('num_titles')\n",
    "            ) \\\n",
    "            .orderBy(desc('avg_rating'))  # Top-rated genre first\n",
    "\n",
    "        # Get top-rated titles by title type (e.g., movies vs tvseries)\n",
    "        top_rated_title_type = titles_with_ratings \\\n",
    "            .groupBy('titleType') \\\n",
    "            .agg(\n",
    "                avg('averageRating').alias('avg_rating'),\n",
    "                count('*').alias('num_titles')\n",
    "            ) \\\n",
    "            .orderBy(desc('avg_rating'))  # Top-rated title type first\n",
    "\n",
    "        # Get top-rated titles overall\n",
    "        top_rated_overall = titles_with_ratings \\\n",
    "            .select('tconst', 'primaryTitle', 'averageRating', 'titleType') \\\n",
    "            .orderBy(desc('averageRating')) \\\n",
    "            .limit(10)  # You can adjust the number of top titles\n",
    "\n",
    "        # Combine all results into one DataFrame for a comprehensive overview\n",
    "        top_rated = {\n",
    "            \"top_rated_genre\": top_rated_genre,\n",
    "            \"top_rated_title_type\": top_rated_title_type,\n",
    "            \"top_rated_overall\": top_rated_overall\n",
    "        }\n",
    "\n",
    "        return top_rated\n",
    "    def analyze_rating_distribution(\n",
    "        titles_path, \n",
    "        ratings_path, \n",
    "        crew_path=None, \n",
    "        principals_path=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Analyze the distribution of ratings across IMDb titles.\n",
    "\n",
    "        :param titles_path: Path to title.basics.tsv.gz\n",
    "        :param ratings_path: Path to title.ratings.tsv.gz\n",
    "        :param crew_path: Optional path to title.crew.tsv.gz\n",
    "        :param principals_path: Optional path to title.principals.tsv.gz\n",
    "        :return: DataFrame with rating distribution metrics\n",
    "        \"\"\"\n",
    "        # Initialize Spark Session\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Rating Distribution Analysis\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        # Read input files\n",
    "        titles_df = spark.read.csv(\n",
    "            titles_path, \n",
    "            sep='\\t', \n",
    "            header=True, \n",
    "            nullValue='\\\\N'\n",
    "        )\n",
    "\n",
    "        ratings_df = spark.read.csv(\n",
    "            ratings_path, \n",
    "            sep='\\t', \n",
    "            header=True, \n",
    "            nullValue='\\\\N'\n",
    "        )\n",
    "\n",
    "        # Filter out adult content and invalid titles\n",
    "        filtered_titles = titles_df.filter(\n",
    "            (col('isAdult') == '0') & \n",
    "            (col('genres') != '\\\\N') & \n",
    "            (col('titleType').isin(['movie', 'tvseries']))\n",
    "        )\n",
    "\n",
    "        # Convert ratings to numeric types\n",
    "        ratings_df = ratings_df.withColumn(\n",
    "            'averageRating', \n",
    "            col('averageRating').cast(DoubleType())\n",
    "        ).withColumn(\n",
    "            'numVotes', \n",
    "            col('numVotes').cast('integer')\n",
    "        )\n",
    "\n",
    "        # Join titles with ratings\n",
    "        titles_with_ratings = filtered_titles.join(\n",
    "            ratings_df, \n",
    "            filtered_titles['tconst'] == ratings_df['tconst'], \n",
    "            'left'\n",
    "        )\n",
    "\n",
    "        # 1. Overall Distribution of Ratings\n",
    "        rating_distribution = titles_with_ratings \\\n",
    "            .groupBy('averageRating') \\\n",
    "            .agg(\n",
    "                count('*').alias('num_titles')\n",
    "            ) \\\n",
    "            .orderBy(desc('averageRating'))  # Sort by rating value\n",
    "\n",
    "        # 2. Rating Ranges: Create categories like 0-2, 2-4, 4-6, etc.\n",
    "        rating_ranges = titles_with_ratings \\\n",
    "            .withColumn('rating_range', \n",
    "                        when(col('averageRating') < 2, '0-2')\n",
    "                        .when(col('averageRating') < 4, '2-4')\n",
    "                        .when(col('averageRating') < 6, '4-6')\n",
    "                        .when(col('averageRating') < 8, '6-8')\n",
    "                        .otherwise('8-10')\n",
    "            ) \\\n",
    "            .groupBy('rating_range') \\\n",
    "            .agg(\n",
    "                count('*').alias('num_titles')\n",
    "            ) \\\n",
    "            .orderBy('rating_range')\n",
    "\n",
    "        # 3. Plotting the Distribution using a Histogram\n",
    "        ratings_data = titles_with_ratings.select('averageRating').rdd.flatMap(lambda x: x).collect()\n",
    "        \n",
    "        # Plot the distribution\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.hist(ratings_data, bins=20, edgecolor='black', color='skyblue')\n",
    "        plt.title(\"Distribution of IMDb Ratings\")\n",
    "        plt.xlabel('Rating')\n",
    "        plt.ylabel('Number of Titles')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        return {\n",
    "            \"rating_distribution\": rating_distribution,\n",
    "            \"rating_ranges\": rating_ranges\n",
    "        }\n",
    "    \n",
    "    def analyze_ratings_by_title_type(\n",
    "        titles_df, \n",
    "        ratings_df, \n",
    "        crew_path=None, \n",
    "        principals_path=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Analyze the correlation between ratings and title type (movie, tvseries) using IMDb datasets.\n",
    "\n",
    "        :param titles_path: Path to title.basics.tsv.gz\n",
    "        :param ratings_path: Path to title.ratings.tsv.gz\n",
    "        :param crew_path: Optional path to title.crew.tsv.gz\n",
    "        :param principals_path: Optional path to title.principals.tsv.gz\n",
    "        :return: DataFrame with average ratings per title type and visualizations\n",
    "        \"\"\"\n",
    "        # Initialize Spark Session\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Correlation Between Ratings and Title Type\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        # Filter out adult content and invalid titles\n",
    "        filtered_titles = titles_df.filter(\n",
    "            (col('isAdult') == '0') & \n",
    "            (col('genres') != '\\\\N') & \n",
    "            (col('titleType').isin(['movie', 'tvseries']))\n",
    "        )\n",
    "\n",
    "        # Convert ratings to numeric types\n",
    "        ratings_df = ratings_df.withColumn(\n",
    "            'averageRating', \n",
    "            col('averageRating').cast(DoubleType())\n",
    "        ).withColumn(\n",
    "            'numVotes', \n",
    "            col('numVotes').cast('integer')\n",
    "        )\n",
    "\n",
    "        # Join titles with ratings\n",
    "        titles_with_ratings = filtered_titles.join(\n",
    "            ratings_df, \n",
    "            filtered_titles['tconst'] == ratings_df['tconst'], \n",
    "            'left'\n",
    "        )\n",
    "\n",
    "        # 1. Calculate the average rating by title type (movie, tvseries)\n",
    "        avg_rating_by_title_type = titles_with_ratings \\\n",
    "            .groupBy('titleType') \\\n",
    "            .agg(\n",
    "                avg('averageRating').alias('avg_rating'),\n",
    "                count('*').alias('num_titles')\n",
    "            ) \\\n",
    "            .orderBy(desc('avg_rating'))\n",
    "         # 2. Visualize ratings by title type (boxplot or histogram)\n",
    "        title_type_data = titles_with_ratings.select('averageRating', 'titleType').toPandas()\n",
    "\n",
    "        # Set up the plot\n",
    "        plt.figure(figsize=(10,6))\n",
    "        sns.boxplot(data=title_type_data, x='titleType', y='averageRating', palette=\"Set2\")\n",
    "        plt.title('Distribution of Ratings by Title Type')\n",
    "        plt.xlabel('Title Type')\n",
    "        plt.ylabel('Average Rating')\n",
    "        plt.show()\n",
    "        # Optional: If you want to perform a t-test or further statistical analysis,\n",
    "        # you could extract the ratings for each title type and compare them.\n",
    "\n",
    "        return avg_rating_by_title_type\n",
    "    def analyze_director_writer_performance(\n",
    "        titles_df, \n",
    "        ratings_df, \n",
    "        crew_df, \n",
    "        principals_df\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Analyze the performance metrics of directors and writers based on IMDb datasets.\n",
    "        Metrics include average rating, total votes, number of titles, and weighted popularity.\n",
    "\n",
    "        :param titles_path: Path to title.basics.tsv.gz\n",
    "        :param ratings_path: Path to title.ratings.tsv.gz\n",
    "        :param crew_path: Path to title.crew.tsv.gz\n",
    "        :param principals_path: Path to title.principals.tsv.gz\n",
    "        :return: DataFrame with performance metrics for directors and writers\n",
    "        \"\"\"\n",
    "        # Initialize Spark Session\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Director and Writer Performance Analysis\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "\n",
    "        # Filter out adult content and invalid titles\n",
    "        filtered_titles = titles_df.filter(\n",
    "            (col('isAdult') == '0') & \n",
    "            (col('genres') != '\\\\N') & \n",
    "            (col('titleType').isin(['movie', 'tvseries']))\n",
    "        )\n",
    "\n",
    "        # Convert ratings to numeric types\n",
    "        ratings_df = ratings_df.withColumn(\n",
    "            'averageRating', \n",
    "            col('averageRating').cast(DoubleType())\n",
    "        ).withColumn(\n",
    "            'numVotes', \n",
    "            col('numVotes').cast('integer')\n",
    "        )\n",
    "\n",
    "        # Join titles with ratings\n",
    "        titles_with_ratings = filtered_titles.join(\n",
    "            ratings_df, \n",
    "            filtered_titles['tconst'] == ratings_df['tconst'], \n",
    "            'left'\n",
    "        )\n",
    "\n",
    "        # Director Performance Metrics\n",
    "        directors_df = crew_df.filter(col('job') == 'Director') \\\n",
    "            .select('tconst', 'nconst').distinct()  # Only distinct directors for each title\n",
    "\n",
    "        # Join director data with title ratings\n",
    "        directors_with_ratings = titles_with_ratings.join(\n",
    "            directors_df, \n",
    "            titles_with_ratings['tconst'] == directors_df['tconst'],\n",
    "            'inner'\n",
    "        )\n",
    "\n",
    "        # Aggregate metrics for directors\n",
    "        director_performance = directors_with_ratings \\\n",
    "            .groupBy('nconst') \\\n",
    "            .agg(\n",
    "                avg('averageRating').alias('avg_rating'),\n",
    "                count('tconst').alias('num_titles'),\n",
    "                sum('numVotes').alias('total_votes'),\n",
    "                (avg('averageRating') * sum('numVotes')).alias('weighted_popularity')\n",
    "            ) \\\n",
    "            .orderBy(desc('weighted_popularity'))  # Sort by weighted popularity\n",
    "\n",
    "        # Writer Performance Metrics\n",
    "        writers_df = principals_df.filter(col('category') == 'writer') \\\n",
    "            .select('tconst', 'nconst').distinct()  # Only distinct writers for each title\n",
    "\n",
    "        # Join writer data with title ratings\n",
    "        writers_with_ratings = titles_with_ratings.join(\n",
    "            writers_df, \n",
    "            titles_with_ratings['tconst'] == writers_df['tconst'],\n",
    "            'inner'\n",
    "        )\n",
    "\n",
    "        # Aggregate metrics for writers\n",
    "        writer_performance = writers_with_ratings \\\n",
    "            .groupBy('nconst') \\\n",
    "            .agg(\n",
    "                avg('averageRating').alias('avg_rating'),\n",
    "                count('tconst').alias('num_titles'),\n",
    "                sum('numVotes').alias('total_votes'),\n",
    "                (avg('averageRating') * sum('numVotes')).alias('weighted_popularity')\n",
    "            ) \\\n",
    "            .orderBy(desc('weighted_popularity'))  # Sort by weighted popularity\n",
    "\n",
    "        # Combine director and writer performance data\n",
    "        combined_performance = director_performance.unionByName(writer_performance)\n",
    "\n",
    "        return combined_performance\n",
    "    def analyze_crew_performance_and_ratings(\n",
    "        titles_df, \n",
    "        ratings_df, \n",
    "        crew_df, \n",
    "        principals_df\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Analyze the correlation between crew members (e.g., directors, writers) and title ratings.\n",
    "        The metrics include average rating, number of titles, total votes, and weighted popularity.\n",
    "\n",
    "        :param titles_df: Path to title.basics.tsv.gz\n",
    "        :param ratings_df: Path to title.ratings.tsv.gz\n",
    "        :param crew_df: Path to title.crew.tsv.gz\n",
    "        :param principals_df: Path to title.principals.tsv.gz\n",
    "        :return: DataFrame with performance metrics for crew members (directors, writers) and their correlation with ratings\n",
    "        \"\"\"\n",
    "        # Initialize Spark Session\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Crew Performance and Ratings Analysis\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        # Filter out adult content and invalid titles\n",
    "        filtered_titles = titles_df.filter(\n",
    "            (col('isAdult') == '0') & \n",
    "            (col('genres') != '\\\\N') & \n",
    "            (col('titleType').isin(['movie', 'tvseries']))\n",
    "        )\n",
    "\n",
    "        # Convert ratings to numeric types\n",
    "        ratings_df = ratings_df.withColumn(\n",
    "            'averageRating', \n",
    "            col('averageRating').cast(DoubleType())\n",
    "        ).withColumn(\n",
    "            'numVotes', \n",
    "            col('numVotes').cast('integer')\n",
    "        )\n",
    "\n",
    "        # Join titles with ratings\n",
    "        titles_with_ratings = filtered_titles.join(\n",
    "            ratings_df, \n",
    "            filtered_titles['tconst'] == ratings_df['tconst'], \n",
    "            'left'\n",
    "        )\n",
    "\n",
    "        # Director Performance Metrics (from crew_df)\n",
    "        directors_df = crew_df.filter(col('job') == 'Director') \\\n",
    "            .select('tconst', 'nconst').distinct()  # Only distinct directors for each title\n",
    "\n",
    "        # Join director data with title ratings\n",
    "        directors_with_ratings = titles_with_ratings.join(\n",
    "            directors_df, \n",
    "            titles_with_ratings['tconst'] == directors_df['tconst'],\n",
    "            'inner'\n",
    "        )\n",
    "\n",
    "        # Aggregate metrics for directors\n",
    "        director_performance = directors_with_ratings \\\n",
    "            .groupBy('nconst') \\\n",
    "            .agg(\n",
    "                avg('averageRating').alias('avg_rating'),\n",
    "                count('tconst').alias('num_titles'),\n",
    "                sum('numVotes').alias('total_votes'),\n",
    "                (avg('averageRating') * sum('numVotes')).alias('weighted_popularity')\n",
    "            ) \\\n",
    "            .orderBy(desc('weighted_popularity'))  # Sort by weighted popularity\n",
    "\n",
    "        # Writer Performance Metrics (from principals_df)\n",
    "        writers_df = principals_df.filter(col('category') == 'writer') \\\n",
    "            .select('tconst', 'nconst').distinct()  # Only distinct writers for each title\n",
    "\n",
    "        # Join writer data with title ratings\n",
    "        writers_with_ratings = titles_with_ratings.join(\n",
    "            writers_df, \n",
    "            titles_with_ratings['tconst'] == writers_df['tconst'],\n",
    "            'inner'\n",
    "        )\n",
    "\n",
    "        # Aggregate metrics for writers\n",
    "        writer_performance = writers_with_ratings \\\n",
    "            .groupBy('nconst') \\\n",
    "            .agg(\n",
    "                avg('averageRating').alias('avg_rating'),\n",
    "                count('tconst').alias('num_titles'),\n",
    "                sum('numVotes').alias('total_votes'),\n",
    "                (avg('averageRating') * sum('numVotes')).alias('weighted_popularity')\n",
    "            ) \\\n",
    "            .orderBy(desc('weighted_popularity'))  # Sort by weighted popularity\n",
    "\n",
    "        # Combine director and writer performance data\n",
    "        combined_performance = director_performance.unionByName(writer_performance)\n",
    "\n",
    "        # Optionally: Analyze correlation or perform statistical tests here if needed\n",
    "        # This could include looking at correlations between weighted popularity and ratings, etc.\n",
    "\n",
    "        return combined_performance\n",
    "    def identify_consistently_high_performing_crew(\n",
    "        titles_df, \n",
    "        ratings_df, \n",
    "        crew_df, \n",
    "        principals_df,\n",
    "        avg_rating_threshold=8.0,  # Threshold for \"high-performing\" average rating\n",
    "        min_titles_threshold=5     # Minimum number of titles to consider consistency\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Identify consistently high-performing directors and writers based on IMDb ratings and votes.\n",
    "        \n",
    "        :param titles_path: Path to title.basics.tsv.gz\n",
    "        :param ratings_path: Path to title.ratings.tsv.gz\n",
    "        :param crew_path: Path to title.crew.tsv.gz\n",
    "        :param principals_path: Path to title.principals.tsv.gz\n",
    "        :param avg_rating_threshold: The threshold for high-performing average ratings (default is 8.0)\n",
    "        :param min_titles_threshold: Minimum number of titles to be considered as consistently high-performing (default is 5)\n",
    "        :return: DataFrame with consistently high-performing directors and writers\n",
    "        \"\"\"\n",
    "        # Initialize Spark Session\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Consistently High-Performing Crew Analysis\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "\n",
    "        # Filter out adult content and invalid titles\n",
    "        filtered_titles = titles_df.filter(\n",
    "            (col('isAdult') == '0') & \n",
    "            (col('genres') != '\\\\N') & \n",
    "            (col('titleType').isin(['movie', 'tvseries']))\n",
    "        )\n",
    "\n",
    "        # Convert ratings to numeric types\n",
    "        ratings_df = ratings_df.withColumn(\n",
    "            'averageRating', \n",
    "            col('averageRating').cast(DoubleType())\n",
    "        ).withColumn(\n",
    "            'numVotes', \n",
    "            col('numVotes').cast('integer')\n",
    "        )\n",
    "\n",
    "        # Join titles with ratings\n",
    "        titles_with_ratings = filtered_titles.join(\n",
    "            ratings_df, \n",
    "            filtered_titles['tconst'] == ratings_df['tconst'], \n",
    "            'left'\n",
    "        )\n",
    "\n",
    "        # Director Performance Metrics (from crew_df)\n",
    "        directors_df = crew_df.filter(col('job') == 'Director') \\\n",
    "            .select('tconst', 'nconst').distinct()  # Only distinct directors for each title\n",
    "\n",
    "        # Join director data with title ratings\n",
    "        directors_with_ratings = titles_with_ratings.join(\n",
    "            directors_df, \n",
    "            titles_with_ratings['tconst'] == directors_df['tconst'],\n",
    "            'inner'\n",
    "        )\n",
    "\n",
    "        # Aggregate metrics for directors\n",
    "        director_performance = directors_with_ratings \\\n",
    "            .groupBy('nconst') \\\n",
    "            .agg(\n",
    "                avg('averageRating').alias('avg_rating'),\n",
    "                count('tconst').alias('num_titles'),\n",
    "                sum('numVotes').alias('total_votes'),\n",
    "                (avg('averageRating') * sum('numVotes')).alias('weighted_popularity')\n",
    "            ) \\\n",
    "            .filter(\n",
    "                (col('avg_rating') >= avg_rating_threshold) &  # Apply average rating threshold\n",
    "                (col('num_titles') >= min_titles_threshold)   # Apply minimum number of titles threshold\n",
    "            ) \\\n",
    "            .orderBy(desc('avg_rating'))  # Sort by avg rating\n",
    "\n",
    "        # Writer Performance Metrics (from principals_df)\n",
    "        writers_df = principals_df.filter(col('category') == 'writer') \\\n",
    "            .select('tconst', 'nconst').distinct()  # Only distinct writers for each title\n",
    "\n",
    "        # Join writer data with title ratings\n",
    "        writers_with_ratings = titles_with_ratings.join(\n",
    "            writers_df, \n",
    "            titles_with_ratings['tconst'] == writers_df['tconst'],\n",
    "            'inner'\n",
    "        )\n",
    "\n",
    "        # Aggregate metrics for writers\n",
    "        writer_performance = writers_with_ratings \\\n",
    "            .groupBy('nconst') \\\n",
    "            .agg(\n",
    "                avg('averageRating').alias('avg_rating'),\n",
    "                count('tconst').alias('num_titles'),\n",
    "                sum('numVotes').alias('total_votes'),\n",
    "                (avg('averageRating') * sum('numVotes')).alias('weighted_popularity')\n",
    "            ) \\\n",
    "            .filter(\n",
    "                (col('avg_rating') >= avg_rating_threshold) &  # Apply average rating threshold\n",
    "                (col('num_titles') >= min_titles_threshold)   # Apply minimum number of titles threshold\n",
    "            ) \\\n",
    "            .orderBy(desc('avg_rating'))  # Sort by avg rating\n",
    "\n",
    "        # Combine director and writer performance data\n",
    "        combined_performance = director_performance.unionByName(writer_performance)\n",
    "\n",
    "        return combined_performance\n",
    "    def analyze_rating_variance_by_title_type(\n",
    "        titles_df, \n",
    "        ratings_df\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Analyze the variance in ratings across different title types using IMDb datasets.\n",
    "\n",
    "        :param titles_path: Path to title.basics.tsv.gz\n",
    "        :param ratings_path: Path to title.ratings.tsv.gz\n",
    "        :return: DataFrame with rating variance, average rating, and title count by title type\n",
    "        \"\"\"\n",
    "        # Initialize Spark Session\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Rating Variance by Title Type\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "        # Filter out adult content and invalid titles\n",
    "        filtered_titles = titles_df.filter(\n",
    "            (col('isAdult') == '0') & \n",
    "            (col('titleType').isNotNull())\n",
    "        )\n",
    "\n",
    "        # Convert ratings to numeric types\n",
    "        ratings_df = ratings_df.withColumn(\n",
    "            'averageRating', \n",
    "            col('averageRating').cast(DoubleType())\n",
    "        ).withColumn(\n",
    "            'numVotes', \n",
    "            col('numVotes').cast('integer')\n",
    "        )\n",
    "\n",
    "        # Join titles with ratings\n",
    "        titles_with_ratings = filtered_titles.join(\n",
    "            ratings_df, \n",
    "            filtered_titles['tconst'] == ratings_df['tconst'], \n",
    "            'inner'\n",
    "        )\n",
    "\n",
    "        # Calculate variance, average rating, and count by title type\n",
    "        rating_variance_by_type = titles_with_ratings \\\n",
    "            .groupBy('titleType') \\\n",
    "            .agg(\n",
    "                var_pop('averageRating').alias('rating_variance'),\n",
    "                avg('averageRating').alias('avg_rating'),\n",
    "                count('tconst').alias('num_titles')\n",
    "            ) \\\n",
    "            .orderBy(desc('rating_variance'))  # Sort by variance descending\n",
    "\n",
    "        return rating_variance_by_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/25 23:27:31 WARN Utils: Your hostname, duong291-VMware-Virtual-Platform resolves to a loopback address: 127.0.0.1; using 192.168.80.128 instead (on interface ens33)\n",
      "24/11/25 23:27:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/25 23:27:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = create_spark_session()\n",
    "# Đọc file Parquet\n",
    "loader = IMDbDataLoader(spark, \"hdfs:///hadoop/data/parquet/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df = loader.load_titles()\n",
    "rating_df = loader.load_ratings()\n",
    "names_df = loader.load_names()\n",
    "akas_df = loader.load_akas()\n",
    "episode_df = loader.load_episodes()\n",
    "principal_df = loader.load_principals()\n",
    "crew_df = loader.load_crews()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================Titles Schema====================\n",
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- titleType: string (nullable = true)\n",
      " |-- primaryTitle: string (nullable = true)\n",
      " |-- originalTitle: string (nullable = true)\n",
      " |-- isAdult: string (nullable = true)\n",
      " |-- startYear: string (nullable = true)\n",
      " |-- endYear: string (nullable = true)\n",
      " |-- runtimeMinutes: string (nullable = true)\n",
      " |-- genres: string (nullable = true)\n",
      "\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+---------------+\n",
      "|    tconst|titleType|        primaryTitle|       originalTitle|isAdult|startYear|endYear|runtimeMinutes|         genres|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+---------------+\n",
      "| tt7567992|tvEpisode|       Episode #1.39|       Episode #1.39|      0|     2012|   NULL|          NULL|          Drama|\n",
      "| tt3714186|tvEpisode|       Super Airship|       Super Airship|      0|     2014|   NULL|            44|    Documentary|\n",
      "|tt29790156|tvEpisode|Vanessa Bell Call...|Vanessa Bell Call...|      0|     2023|   NULL|          NULL|      Talk-Show|\n",
      "|tt10126220|tvEpisode|Joker Trailer and...|Joker Trailer and...|      0|     2019|   NULL|          NULL|           News|\n",
      "| tt3120808|tvEpisode|               Spoon|               Spoon|      0|     2011|   NULL|          NULL|Music,Talk-Show|\n",
      "+----------+---------+--------------------+--------------------+-------+---------+-------+--------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "===================Rating Schema====================\n",
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- averageRating: string (nullable = true)\n",
      " |-- numVotes: string (nullable = true)\n",
      "\n",
      "+---------+-------------+--------+\n",
      "|   tconst|averageRating|numVotes|\n",
      "+---------+-------------+--------+\n",
      "|tt0000001|          5.7|    2102|\n",
      "|tt0000002|          5.6|     282|\n",
      "|tt0000003|          6.5|    2121|\n",
      "|tt0000004|          5.4|     182|\n",
      "|tt0000005|          6.2|    2852|\n",
      "+---------+-------------+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "===================Names Schema====================\n",
      "root\n",
      " |-- nconst: string (nullable = true)\n",
      " |-- primaryName: string (nullable = true)\n",
      " |-- birthYear: string (nullable = true)\n",
      " |-- deathYear: string (nullable = true)\n",
      " |-- primaryProfession: string (nullable = true)\n",
      " |-- knownForTitles: string (nullable = true)\n",
      "\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "|   nconst|    primaryName|birthYear|deathYear|   primaryProfession|      knownForTitles|\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "|nm0000001|   Fred Astaire|     1899|     1987|actor,miscellaneo...|tt0050419,tt00723...|\n",
      "|nm0000002|  Lauren Bacall|     1924|     2014|actress,soundtrac...|tt0037382,tt00752...|\n",
      "|nm0000003|Brigitte Bardot|     1934|     NULL|actress,music_dep...|tt0057345,tt00491...|\n",
      "|nm0000004|   John Belushi|     1949|     1982|actor,writer,musi...|tt0072562,tt00779...|\n",
      "|nm0000005| Ingmar Bergman|     1918|     2007|writer,director,a...|tt0050986,tt00694...|\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "===================Akas Schema====================\n",
      "root\n",
      " |-- titleId: string (nullable = true)\n",
      " |-- ordering: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- language: string (nullable = true)\n",
      " |-- types: string (nullable = true)\n",
      " |-- attributes: string (nullable = true)\n",
      " |-- isOriginalTitle: string (nullable = true)\n",
      "\n",
      "+----------+--------+--------------------+------+--------+--------+----------+---------------+\n",
      "|   titleId|ordering|               title|region|language|   types|attributes|isOriginalTitle|\n",
      "+----------+--------+--------------------+------+--------+--------+----------+---------------+\n",
      "| tt7310226|       3|       एपिसोड #1.122|    IN|      hi|    NULL|      NULL|              0|\n",
      "|tt21971816|       4|       Épisode #1.15|    FR|      fr|    NULL|      NULL|              0|\n",
      "|tt14837298|       1|    578 days waiting|  NULL|    NULL|original|      NULL|              1|\n",
      "|tt31835460|       6|        Folge #1.225|    DE|      de|    NULL|      NULL|              0|\n",
      "|tt33284890|       1|Les grands voyageurs|  NULL|    NULL|original|      NULL|              1|\n",
      "+----------+--------+--------------------+------+--------+--------+----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "===================Episode Schema====================\n",
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- parentTconst: string (nullable = true)\n",
      " |-- seasonNumber: string (nullable = true)\n",
      " |-- episodeNumber: string (nullable = true)\n",
      "\n",
      "+----------+------------+------------+-------------+\n",
      "|    tconst|parentTconst|seasonNumber|episodeNumber|\n",
      "+----------+------------+------------+-------------+\n",
      "| tt1000577|   tt0274988|           3|            3|\n",
      "|tt29589623|  tt10127406|           1|         2724|\n",
      "| tt1535276|   tt1495168|           1|            3|\n",
      "|tt31960291|  tt31912359|           1|            2|\n",
      "|tt13018086|   tt5209414|           5|           77|\n",
      "+----------+------------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "===================Principal Schema====================\n",
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- ordering: string (nullable = true)\n",
      " |-- nconst: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- characters: string (nullable = true)\n",
      "\n",
      "+---------+--------+---------+---------------+--------------------+----------+\n",
      "|   tconst|ordering|   nconst|       category|                 job|characters|\n",
      "+---------+--------+---------+---------------+--------------------+----------+\n",
      "|tt0000001|       1|nm1588970|           self|                NULL|  [\"Self\"]|\n",
      "|tt0000001|       2|nm0005690|       director|                NULL|      NULL|\n",
      "|tt0000001|       3|nm0005690|       producer|            producer|      NULL|\n",
      "|tt0000001|       4|nm0374658|cinematographer|director of photo...|      NULL|\n",
      "|tt0000002|       1|nm0721526|       director|                NULL|      NULL|\n",
      "+---------+--------+---------+---------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "===================Crew Schema====================\n",
      "root\n",
      " |-- tconst: string (nullable = true)\n",
      " |-- directors: string (nullable = true)\n",
      " |-- writers: string (nullable = true)\n",
      "\n",
      "+----------+---------+-------------------+\n",
      "|    tconst|directors|            writers|\n",
      "+----------+---------+-------------------+\n",
      "|tt10534056|nm2163736|          nm2166814|\n",
      "| tt6979356|     NULL|               NULL|\n",
      "| tt1488297|nm1646438|               NULL|\n",
      "| tt8464022|     NULL|nm0179153,nm0179181|\n",
      "|tt15864432|     NULL|               NULL|\n",
      "+----------+---------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"===================Titles Schema====================\")\n",
    "titles_df.printSchema(5)\n",
    "titles_df.show(5)\n",
    "print(\"===================Rating Schema====================\")\n",
    "rating_df.printSchema(5)\n",
    "rating_df.show(5)\n",
    "print(\"===================Names Schema====================\")\n",
    "names_df.printSchema(5)\n",
    "names_df.show(5)\n",
    "print(\"===================Akas Schema====================\")\n",
    "akas_df.printSchema(5)\n",
    "akas_df.show(5)\n",
    "print(\"===================Episode Schema====================\")\n",
    "episode_df.printSchema(5)\n",
    "episode_df.show(5)\n",
    "print(\"===================Principal Schema====================\")\n",
    "principal_df.printSchema(5)\n",
    "principal_df.show(5)\n",
    "print(\"===================Crew Schema====================\")\n",
    "crew_df.printSchema(5)\n",
    "crew_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5740/53701818.py:29: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n",
      "24/11/26 00:05:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/11/26 00:05:10 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Import MovieAnalyzer and MovieVisualizer classes\n",
    "# (Assume these are imported or defined in the same script)\n",
    "\n",
    "# Initialize MovieAnalyzer\n",
    "analyzer = MovieAnalyzer(titles_df, crew_df, principal_df, rating_df)\n",
    "\n",
    "# Perform analyses\n",
    "genre_distribution = analyzer.get_genre_distribution()\n",
    "director_productivity = analyzer.get_director_productivity()\n",
    "job_distribution = analyzer.get_job_distribution()\n",
    "multi_role_people = analyzer.get_multi_role_people()\n",
    "collaboration_network = analyzer.get_collaboration_network()\n",
    "top_rated_movies = analyzer.get_top_rated_movies()\n",
    "\n",
    "# Initialize MovieVisualizer\n",
    "visualizer = MovieVisualizer()\n",
    "\n",
    "# Visualize and save the plots\n",
    "genre_plot = visualizer.plot_genre_distribution(genre_distribution)\n",
    "genre_plot.savefig(\"genre_distribution.png\")\n",
    "\n",
    "job_plot = visualizer.plot_job_distribution(job_distribution)\n",
    "job_plot.savefig(\"job_distribution.png\")\n",
    "\n",
    "director_plot = visualizer.plot_director_productivity(director_productivity)\n",
    "director_plot.savefig(\"director_productivity.png\")\n",
    "\n",
    "top_rated_plot = visualizer.plot_top_rated_movies(top_rated_movies)\n",
    "top_rated_plot.savefig(\"top_rated_movies.png\")\n",
    "\n",
    "# Scatter plot for collaboration network\n",
    "collab_df = collaboration_network.toPandas()\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(collab_df['director_id'], collab_df['producer_id'], s=collab_df['count'] * 10, alpha=0.6)\n",
    "plt.title(\"Director-Producer Collaboration Network\")\n",
    "plt.xlabel(\"Director ID\")\n",
    "plt.ylabel(\"Producer ID\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"collaboration_network.png\")\n",
    "\n",
    "# Print multi-role contributors for quick reference\n",
    "multi_role_people.show()\n",
    "\n",
    "# Stop Spark session\n",
    "spark.stop()\n",
    "\n",
    "print(\"Analysis completed. Plots saved as images.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
